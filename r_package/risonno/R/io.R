#@include 
NULL
#' Read data from a result file.
#' 
#' This function is used to convert all the information
#' contained in a result file generated by PSV into an R data.table.
#'
#' @param what an object which file to load and, optionally, associated variables/conditions (see details).
#' @param min_time exclude data before min_time (in seconds). This time is relative to the start of the experiement.
#' @param max_time exclude data after max_time (in seconds). This time is relative to the start of the experiement.
#' @param reference_hour the hour, in the day, to use as t0 reference. When no reference hour, all time is relative to the start of the experiment.
#' @param FUN an optionnal function to be applied to each ROI (i.e. a data.table), immeridatly after being loaded. 
#' @param ... extra arguments to be passed to \code{FUN}
#' @return A data table where every row is an individual measurment (at a given time) in a unique ROI, and from a unique result file/experiment.
#' The time (column`t`) is expressed in seconds. Distance units (e.g. xy position, height/width) are expressed as a fraction of the ROI width.
#' @details `what` can be one of two things:
#' \itemize{
#'  \item{A character vector. }{In which case, it is assumed that each element is the path to a different file to load.}
#'  \item{A dataframe. }{The dataframe \emph{must} have a column named `path`. 
#' Arbitrary column can be added to map experimental condition to file name.
#' In addition, the dataframe can have a column named `roi_id`. When it is defined, only the specified combinations of file and roi_id
#' will be loaded. This allows to map additionnal conditions (data frame columns) to specific ROIs/files.
#' When additionnal conditions are provided, they will result in creation of custom columns in the output of this function.}
#' }
#'
#' @note Analysis of many long (sevaral days) recording can use a large amount of RAM. 
#' Therefore, it can sometimes be advantageaous to load an process ROIs one by one.
#' @examples
#'
#' # First of all, let us load files from the data sample with the package.
#' # Most likely, you will already have your own data files.
#' sample_files <- c("validation.db", "sample_1.db","sample_2.db")
#' # Extract the files in your computer
#' paths <- sapply(sample_files, loadSampleData)
#' # Now, `paths` his is just a vector of file names:
#' print(paths)
#' #################
#' #################
#' # Case 1: load ALL ROIS from a SINGLE FILE
#' validation_data_file <- paths[1]
#' # `validation_data_file` is simply the path to the db file in your computer
#' dt <- loadPsvData(validation_data_file)
#' 
#' ###############
#' # Case 2: load ALL ROIS from MULTIPLE FILES
#' # we pass all the files we want to load as thw `what` argument
#' dt <- loadPsvData(paths)
#' # Note the column `file` in dt. It tells us which file/experiement 
#' # each measurment originates from.
#' print(dt)
#'
#' ###############
#' # Case 3: load ALL ROIS from MULTIPLE FILES AND add CONDITIONS
#' # Let us imagine that each file/experiement
#' # is for a different experiemental condition.
#' # We can encode this information in a 'master-table' (data frame) where a column
#' # named `path` maps experiemental condition(s). For instance 3 different treatments:
#' master_table <- data.frame(path=paths, treatment=c("control", "drug_A", "drug_B"))
#' # Let us check our table:
#' print(master_table)
#' dt <- loadPsvData(master_table)
#' # Note that `dt` now contains a column for your treatment.
#' # This makes it easier to perform things such as average per treatment.
#' print(dt)
#' ###############
#' # Case 4: load SELECTED ROIS from MULTIPLE FILE WITH CONDITIONS
#' # Sometimes, different ROIs are for different conditions.
#' # If the master table contains a column names `roi_id`. only the specified ROIs will be added.
#' # Let us assume that we want to replicate case 3, but now we load only the first 20 rois.
#' master_table <- data.frame(path=paths, treatment=c("control", "drug_A", "drug_B"), roi_id=rep(1:20,each= 3))
#' # We could also say that every even ROI is a male, and every odd is a male:
#' master_table$sex <- ifelse(master_table$roi %% 2, "male", "female" )
#' # Note that we have now two conditions.
#' # Let us check our new table:
#' print(master_table)
#' dt <- loadPsvData(master_table)
#' ####################
#' # Case 5: Apply ANALYSIS/function while loading the data.
#' # You can apply a function from this package, or your oan function fo the data as it is being loaded.
#' # For instance, if you wish to peforme a "sleep" annotation:
#' dt <- loadPsvData(paths[1], FUN=sleepAnalysis)
#' # Note that you could of course combine this with more conditions/ROI selection
#' # For most complicated cases, you would have probably generated the 
#' # master-table before analysing the results

#' @seealso \code{\link{loadMetaData}} To display global informations about a specific file. 
#' @export
loadPsvData <- function(what,
				min_time = 0,
				max_time = Inf, 
				reference_hour=NULL,
				verbose=TRUE,
				FUN=NULL,
				...){
	
	# from the `what` argument, we build a `master_table` that we will map to the actual data.
	
	# case 1 what is a file, or a vector of files
	if(is.character(what)){
		# todo check whether file exists
		master_table <- data.table(path=what, file=basename(what))
		# We load all available ROIs since user did not provide ROI info
		master_table <- master_table[,list(
				roi_id=availableROIs(path),
				file=file),by=path]
	}
	else if(is.data.frame(what)){
		
		if(!"path" %in% colnames(what))
			stop("When `what` is a data.frame, it MUST have a column named 'path'")
		master_table <- as.data.table(what)
		#fixme check uniqueness of file/use path as key?
		master_table[,path := as.character(path)]
		master_table[,file := basename(path)]
		
		setkey(master_table,file)
		
		if(!"roi_id" %in% colnames(what)){
			m <- master_table[,list(roi_id=availableROIs(path)),by=key(master_table)]
			master_table <- m[master_table]
		}

		}
	else{
		stop("Unexpected `what` argument!")
		}
	
	setkeyv(master_table,c("file","roi_id"))
	
	l_dt <- lapply(1:nrow(master_table),
			function(i){
				roi_id <- master_table[i,roi_id]
				file <- master_table[i,file]
				path <- master_table[i,path]
				if(verbose)
					print(sprintf("Loading ROI \\#%i from:\n %s",roi_id,path))
					
				out <- loadOneROI(path,	roi_id=roi_id,
									min_time = min_time,
									max_time = max_time, 
									reference_hour=reference_hour)
				if(nrow(out) == 0){
					warning(sprintf("No data in ROI %i, from FILE %s. Skipping",roi_id, path))
					return(NULL)
					}
					
				if(!is.null(FUN))
					out <- FUN(out,...)
				out[,file:=file]
				setkeyv(out,c("file","roi_id"))
				})
				
	l_dt <- l_dt[!sapply(l_dt,is.null)]
	if(length(unique(lapply(l_dt,key))) > 1){
		stop("Data tables do not have the same keys")
		}
	keys <- key(l_dt[[1]])

	out <- rbindlist(l_dt)
	rm(l_dt)
	
	setkeyv(out, keys)
	master_table[out]
}


loadOneROI <- function(
		FILE,
		roi_id, 
		min_time=0, # In  s
		max_time=Inf,
		reference_hour=NULL){
		
		metadata <- loadMetaData(FILE)
		con <- dbConnect(SQLite(), FILE)
		
		var_map <- as.data.table(dbGetQuery(con, "SELECT * FROM VAR_MAP"))
		setkey(var_map, var_name)
		roi_map <- as.data.table(dbGetQuery(con, "SELECT * FROM ROI_MAP"))
		roi_row <- roi_map[roi_idx == roi_id,]
		if(nrow(roi_row) == 0 ){
			warning(sprintf("ROI %i does not exist, skipping",roi_id))
			return(NULL)
		}
		if(max_time == Inf)
			max_time_condition <- ""
		else
			max_time_condition <-  sprintf("AND t < %e", max_time * 1000) 
			
		min_time <- min_time * 1000 
		
		sql_query <- sprintf("SELECT * FROM ROI_%i WHERE t >= %e %s",roi_id,min_time, max_time_condition )
		
		roi_dt <- as.data.table(dbGetQuery(con, sql_query))
		roi_dt[, id := NULL]
		roi_dt[, roi_id := roi_id]
		
		
		if(!is.null(reference_hour)){
			p <- metadata$date_time
			hour_start <- as.numeric(format(p, "%H")) + as.numeric(format(p, "%M")) / 60 +  as.numeric(format(p, "%S")) / 3600
			ms_after_ref <- ((hour_start - reference_hour) %% 24) * 3600 * 1000
			roi_dt[, t:= (t + ms_after_ref) ]
		}
		
		#time_in_seconds
		roi_dt[, t:= t/1e3]
		
		roi_width <- max(c(roi_row[,w], roi_row[,h]))
		for(var_n in var_map$var_name){
			if(var_map[var_n, functional_type] == "distance"){
				roi_dt[, (var_n) := get(var_n) / roi_width]
			}
			if(var_map[var_n, sql_type] == "BOOLEAN"){
				roi_dt[, (var_n) := as.logical(get(var_n))]
			}
		}
		return(roi_dt)
	}

NULL

#' Get metadata from a result file.
#' 
#' This function is used to obtain meta data -- such as `time and date of the experiment' , `aquisition device', `version of the software' and others--
#' contained in a result file generated by PSV.
#'
#' @param FILE the name of the input file.
#' @return A list containing fields for metadata entries
#' @examples
#' \dontrun{
#' FILE <- "result.db"
#' out <- loadMetaData(FILE)
#' names(out)
#' }
#' @seealso \code{\link{loadROIsFromFile}} to obtain raw experiemental data. 
#' @export
loadMetaData <- function(FILE){
	con <- dbConnect(SQLite(), FILE)
	metadata <- dbGetQuery(con, "SELECT * FROM METADATA")
	dbDisconnect(con)
	v <- as.list(metadata$value)
	names(v) <- metadata$field
	#fixme explicitly GMT
	v$date_time <- as.POSIXct(as.integer(v$date_time),origin="1970-01-01",tz = "GMT")
	return(v)		
	}
	


# @include
NULL
#' Read a text file formatted as DAM2 into a single data table
#'
#' This function is used to conveniently change the format of one file from DAM2 to risonno.
#'
#' @param FILE the name of the input file.
#' @param min_time exclude data before min_time (in seconds). This time is relative to the start of the experiement.
#' @param max_time exclude data after max_time (in seconds). This time is relative to the start of the experiement.
#' @return If \code{rois} has only one element, a dataframe. Otherwise, a list of dataframes (one per ROI)
#' @note Analysis of many long (sevaral days) recording can use a large amount of RAM.
#' Therefore, it can sometimes be advantageaous to load an process ROIs one by one.
#' @examples
#' \dontrun{
#' FILE <- "Monitor53.txt"
#' out <- loadDAMFile(FILE)
#' #histogram of x marginal distribution
#' hist(out[roi_id == 1, x], nclass=100)
#' }
#' \dontrun{
#' # More realistec example where we have experiemental conditions, and
#' we want to resample data at 1.0Hz.
#' # First, the conditions:
#' conditions <- cbind(roi_id=1:32, expand.grid(treatment=c(T,F), genotype=LETTERS[1:4]))
#' print(conditions)
#' }
#' @seealso \code{\link{loadMetaData}} To display global informations about the experiment.
#' @export
loadDAMFile <- function(FILE, channels = NULL, min_time = 0, max_time = Inf, interval = 60){
	### hardcodded constants
	DAM_COL_TYPES <- c(
		"integer", "character", "character",
		#rep(NULL, 7), ## these columns are irrelevant, NULL means we will discard them straight away
		rep("double", 32)
		)

	DAM_COL_NAMES <- c("idx", "day_month_year", "time", sprintf("channel_%02d", 1:32))

	dt_list <- fread(FILE, drop=4:10, header = FALSE)
	setnames(dt_list,DAM_COL_NAMES)
	dt_list[,datetime:=paste(day_month_year,time, sep=":")]
	dt_list[,t:=as.POSIXct(strptime(datetime,"%d %b %Y:%H:%M:%S"))]
	#clean table from unused parameters (idx,time, datetime...)
	dt_list[,time:=NULL]
	dt_list[,datetime:=NULL]
	dt_list[,idx:=NULL]
	dt_list[,day_month_year:=NULL]
	#for (i in seq(1,7,1) dt_list[,not_in_use_+i]
	#melting using pacakage reshape
	dt_risonno <- as.data.table(melt(dt_list,id="t"))

    roi_value <- function(channel_string){
        s <- strsplit(channel_string,"_")
        num <- as.integer(sapply(s,function(x) x[2]))
        return(num)
    }
    #get the values on activity
    dt_risonno[,activity:=value]
    dt_risonno[,roi_id:=roi_value(as.character(variable))]
	return(dt_risonno)
}


NULL

loadDAMFiles <- function(FILES, channels = NULL, min_time = 0, max_time = Inf, interval = 60){
	### hardcodded constants
	DAM_COL_TYPES <- c(
		c("integer", "character", "character", "character", "character"),
		rep("NULL", 7), ## these columns are irrelevant, NULL means we will discard them straight away
		rep("double", 32)
		)

	DAM_COL_NAMES <- c("idx", "day", "month", "year", "time",rep(NA, 7), sprintf("channel_%02d", 1:32))
	
	# todo sort files per actual dates before concat
	df_list <- lapply(FILES, function(f){
			read.table(f, colClasses = DAM_COL_TYPES, header = FALSE, col.names=DAM_COL_NAMES)
		})

	df <- do.call("rbind", df_list)
	#quick fix
	df$t <- 1:nrow(df) * interval #(s)
	df$day <- NULL
	df$month <- NULL
	df$year <- NULL
	df$time <- NULL
	
	if(is.null(channels))
		channels <- 1:32
	
	df <- subset(df, t > min_time & t < max_time)
	chans_to_fecth <- sprintf("channel_%02d", channels)
	
	df_l <- lapply(chans_to_fecth, function(x){
			data.frame(t=df$t,activity=df[,x])
		})
	names(df_l) <- chans_to_fecth	
	return(df_l)
}	

NULL
#' TODO
#' 
#' TODO
#' TODO...... . .............. ... . .. . ...... 

#' @export
loadSampleData <- function(name="",list=F){
	db_file <- system.file("data/db_files.tar.xz", package="risonno")
	
	if(list == T){
		content <- untar(db_file, list=T)
		db_files <- content
		out <- basename(content)[dirname(content) != '.']
		return(out)
		}
	if(name == "")
		stop("INVALID FILE NAME. List available files using `list=TRUE`")
	
	d <- tempdir()
	file_name <- file.path("db_files",name)
	r <- untar(db_file, files=file_name,exdir=d)
	if(r == 2){
		unlink(d, recursive=T)
		stop("INVALID FILE NAME. List available files using `list=TRUE`")
		}
	out <-file.path(d,file_name)
	warning("Do not, forget to unlink file")
	return(out)
}

availableROIs <- function(FILE){
	con <- dbConnect(SQLite(), FILE)
	roi_map <- as.data.table(dbGetQuery(con, "SELECT * FROM ROI_MAP"))
	setkey(roi_map, roi_idx)

	available_rois  <- roi_map[ ,roi_idx]
	dbDisconnect(con)
	return(available_rois)
}

